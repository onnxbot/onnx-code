<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - onnx-coverage.info - onnx/common/ir_pb_converter.cc</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">onnx/common</a> - ir_pb_converter.cc<span style="font-size: 80%;"> (source / <a href="ir_pb_converter.cc.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">onnx-coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">220</td>
            <td class="headerCovTableEntry">338</td>
            <td class="headerCovTableEntryLo">65.1 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2018-05-11 14:21:51</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">13</td>
            <td class="headerCovTableEntry">13</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // ATTENTION: The code in this file is highly EXPERIMENTAL.</a>
<span class="lineNum">       2 </span>            : // Adventurous users should note that the APIs will probably change.
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : #include &quot;onnx/common/ir_pb_converter.h&quot;
<span class="lineNum">       5 </span>            : 
<span class="lineNum">       6 </span>            : namespace ONNX_NAMESPACE {
<span class="lineNum">       7 </span>            : 
<span class="lineNum">       8 </span>            : // Part 1: convert ONNX Protobuf to IR
<a name="9"><span class="lineNum">       9 </span>            : std::unique_ptr&lt;Graph&gt; graphProtoToGraph(const ONNX_NAMESPACE::GraphProto&amp; gp, bool nested);</a>
<span class="lineNum">      10 </span>            : 
<span class="lineNum">      11 </span>            : Tensor tensorProtoToTensor(const ONNX_NAMESPACE::TensorProto &amp; tp) {
<span class="lineNum">      12 </span><span class="lineCov">         16 :   Tensor ret;</span>
<span class="lineNum">      13 </span>            : 
<span class="lineNum">      14 </span><span class="lineCov">         48 :   ret.sizes().reserve(tp.dims_size());</span>
<span class="lineNum">      15 </span><span class="lineCov">         57 :   for (int i = 0; i &lt; tp.dims_size(); i++) {</span>
<span class="lineNum">      16 </span><span class="lineCov">          9 :     ret.sizes().push_back(tp.dims(i));</span>
<span class="lineNum">      17 </span><span class="lineCov">          3 :   }</span>
<span class="lineNum">      18 </span>            : 
<span class="lineNum">      19 </span><span class="lineCov">         48 :   ret.elem_type() = tp.data_type();</span>
<span class="lineNum">      20 </span><span class="lineCov">         32 :   switch(tp.data_type()) {</span>
<span class="lineNum">      21 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_FLOAT:
<span class="lineNum">      22 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_COMPLEX64: {
<span class="lineNum">      23 </span><span class="lineCov">          9 :     ret.floats().reserve(tp.float_data_size());</span>
<span class="lineNum">      24 </span><span class="lineCov">         63 :     for (int i = 0; i &lt; tp.float_data_size(); i++) {</span>
<span class="lineNum">      25 </span><span class="lineCov">         54 :       ret.floats().push_back(tp.float_data(i));</span>
<span class="lineNum">      26 </span><span class="lineCov">         18 :     }</span>
<span class="lineNum">      27 </span><span class="lineCov">          3 :     break;</span>
<span class="lineNum">      28 </span>            :   }
<span class="lineNum">      29 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_FLOAT16:
<span class="lineNum">      30 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_BOOL:
<span class="lineNum">      31 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT8:
<span class="lineNum">      32 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT16:
<span class="lineNum">      33 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT32:
<span class="lineNum">      34 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT8:
<span class="lineNum">      35 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT16: {
<span class="lineNum">      36 </span><span class="lineCov">         39 :     ret.int32s().reserve(tp.int32_data_size());</span>
<span class="lineNum">      37 </span><span class="lineCov">         78 :     for (int i = 0; i &lt; tp.int32_data_size(); i++) {</span>
<span class="lineNum">      38 </span><span class="lineCov">         39 :       ret.int32s().push_back(tp.int32_data(i));</span>
<span class="lineNum">      39 </span><span class="lineCov">         13 :     }</span>
<span class="lineNum">      40 </span><span class="lineCov">         13 :     break;</span>
<span class="lineNum">      41 </span>            :   }
<span class="lineNum">      42 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT64: {
<span class="lineNum">      43 </span><span class="lineNoCov">          0 :     ret.int64s().reserve(tp.int64_data_size());</span>
<span class="lineNum">      44 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; tp.int64_data_size(); i++) {</span>
<span class="lineNum">      45 </span><span class="lineNoCov">          0 :       ret.int64s().push_back(tp.int64_data(i));</span>
<span class="lineNum">      46 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">      47 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">      48 </span>            :   }
<span class="lineNum">      49 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT32:
<span class="lineNum">      50 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT64: {
<span class="lineNum">      51 </span><span class="lineNoCov">          0 :     ret.uint64s().reserve(tp.uint64_data_size());</span>
<span class="lineNum">      52 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; tp.uint64_data_size(); i++) {</span>
<span class="lineNum">      53 </span><span class="lineNoCov">          0 :       ret.uint64s().push_back(tp.uint64_data(i));</span>
<span class="lineNum">      54 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">      55 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">      56 </span>            :   }
<span class="lineNum">      57 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_DOUBLE:
<span class="lineNum">      58 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_COMPLEX128: {
<span class="lineNum">      59 </span><span class="lineNoCov">          0 :     ret.doubles().reserve(tp.double_data_size());</span>
<span class="lineNum">      60 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; tp.double_data_size(); i++) {</span>
<span class="lineNum">      61 </span><span class="lineNoCov">          0 :       ret.doubles().push_back(tp.double_data(i));</span>
<span class="lineNum">      62 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">      63 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">      64 </span>            :   }
<span class="lineNum">      65 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_STRING: {
<span class="lineNum">      66 </span><span class="lineNoCov">          0 :     ret.strings().reserve(tp.string_data_size());</span>
<span class="lineNum">      67 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; tp.string_data_size(); i++) {</span>
<span class="lineNum">      68 </span><span class="lineNoCov">          0 :       ret.strings().push_back(tp.string_data(i));</span>
<span class="lineNum">      69 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">      70 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">      71 </span>            :   }
<span class="lineNum">      72 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UNDEFINED:
<span class="lineNum">      73 </span><span class="lineNoCov">          0 :     abort();</span>
<span class="lineNum">      74 </span>            :   }
<span class="lineNum">      75 </span>            : 
<span class="lineNum">      76 </span>            :   // The only way to know if we should be using raw_data or
<span class="lineNum">      77 </span>            :   // &lt;type&gt;_data is to look at which of them is size zero.
<span class="lineNum">      78 </span><span class="lineCov">         32 :   if (tp.has_raw_data()) {</span>
<span class="lineNum">      79 </span><span class="lineNoCov">          0 :     ret.set_raw_data(tp.raw_data());</span>
<span class="lineNum">      80 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">      81 </span>            : 
<span class="lineNum">      82 </span><span class="lineCov">         32 :   if (tp.has_name()) {</span>
<span class="lineNum">      83 </span><span class="lineCov">         64 :     ret.setName(tp.name());</span>
<span class="lineNum">      84 </span><span class="lineCov">         16 :   }</span>
<span class="lineNum">      85 </span><span class="lineCov">         32 :   if (tp.has_segment()) {</span>
<span class="lineNum">      86 </span><span class="lineNoCov">          0 :     ret.set_segment_begin_and_end(tp.segment().begin(), tp.segment().end());</span>
<span class="lineNum">      87 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">      88 </span><span class="lineCov">         16 :   return ret;</span>
<a name="89"><span class="lineNum">      89 </span><span class="lineCov">         32 : }</span></a>
<span class="lineNum">      90 </span>            : 
<span class="lineNum">      91 </span>            : void convertAttribute(const ONNX_NAMESPACE::AttributeProto &amp; ap, Node * n) {
<span class="lineNum">      92 </span><span class="lineCov">         68 :   Symbol sym = Symbol(ap.name());</span>
<span class="lineNum">      93 </span><span class="lineCov">         68 :   switch(ap.type()) {</span>
<span class="lineNum">      94 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_FLOAT:
<span class="lineNum">      95 </span><span class="lineNoCov">          0 :     n-&gt;f_(sym, ap.f());</span>
<span class="lineNum">      96 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">      97 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_FLOATS: {
<span class="lineNum">      98 </span><span class="lineNoCov">          0 :     std::vector&lt;double&gt; floats;</span>
<span class="lineNum">      99 </span><span class="lineNoCov">          0 :     floats.reserve(ap.floats_size());</span>
<span class="lineNum">     100 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; ap.floats_size(); i++) {</span>
<span class="lineNum">     101 </span><span class="lineNoCov">          0 :       floats.push_back(ap.floats(i));</span>
<span class="lineNum">     102 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     103 </span><span class="lineNoCov">          0 :     n-&gt;fs_(sym, std::move(floats));</span>
<span class="lineNum">     104 </span>            :     break;
<span class="lineNum">     105 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     106 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_INT:
<span class="lineNum">     107 </span><span class="lineCov">         14 :     n-&gt;i_(sym, ap.i());</span>
<span class="lineNum">     108 </span><span class="lineCov">         14 :     break;</span>
<span class="lineNum">     109 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_INTS: {
<span class="lineNum">     110 </span><span class="lineCov">         16 :     std::vector&lt;int64_t&gt; ints;</span>
<span class="lineNum">     111 </span><span class="lineCov">         32 :     ints.reserve(ap.ints_size());</span>
<span class="lineNum">     112 </span><span class="lineCov">        174 :     for (int i = 0; i &lt; ap.ints_size(); i++) {</span>
<span class="lineNum">     113 </span><span class="lineCov">         84 :       ints.push_back(ap.ints(i));</span>
<span class="lineNum">     114 </span><span class="lineCov">         42 :     }</span>
<span class="lineNum">     115 </span><span class="lineCov">         16 :     n-&gt;is_(sym, std::move(ints));</span>
<span class="lineNum">     116 </span>            :     break;
<span class="lineNum">     117 </span><span class="lineCov">         16 :   }</span>
<span class="lineNum">     118 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_STRING:
<span class="lineNum">     119 </span><span class="lineNoCov">          0 :     n-&gt;s_(sym, ap.s());</span>
<span class="lineNum">     120 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">     121 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_STRINGS: {
<span class="lineNum">     122 </span><span class="lineNoCov">          0 :     std::vector&lt;std::string&gt; strings;</span>
<span class="lineNum">     123 </span><span class="lineNoCov">          0 :     strings.reserve(ap.strings_size());</span>
<span class="lineNum">     124 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; ap.strings_size(); i++) {</span>
<span class="lineNum">     125 </span><span class="lineNoCov">          0 :       strings.push_back(ap.strings(i));</span>
<span class="lineNum">     126 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     127 </span><span class="lineNoCov">          0 :     n-&gt;ss_(sym, std::move(strings));</span>
<span class="lineNum">     128 </span>            :     break;
<span class="lineNum">     129 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     130 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_TENSOR:
<span class="lineNum">     131 </span><span class="lineCov">         32 :     n-&gt;t_(sym, tensorProtoToTensor(ap.t()));</span>
<span class="lineNum">     132 </span><span class="lineCov">         16 :     break;</span>
<span class="lineNum">     133 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_TENSORS: {
<span class="lineNum">     134 </span><span class="lineNoCov">          0 :     std::vector&lt;Tensor&gt; tensors;</span>
<span class="lineNum">     135 </span><span class="lineNoCov">          0 :     tensors.reserve(ap.tensors_size());</span>
<span class="lineNum">     136 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; ap.tensors_size(); i++) {</span>
<span class="lineNum">     137 </span><span class="lineNoCov">          0 :       tensors.push_back(tensorProtoToTensor(ap.tensors(i)));</span>
<span class="lineNum">     138 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     139 </span><span class="lineNoCov">          0 :     n-&gt;ts_(sym, std::move(tensors));</span>
<span class="lineNum">     140 </span>            :     break;
<span class="lineNum">     141 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     142 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_GRAPH:
<span class="lineNum">     143 </span><span class="lineCov">         20 :     n-&gt;g_(sym, graphProtoToGraph(ap.g(), true));</span>
<span class="lineNum">     144 </span><span class="lineCov">          8 :     break;</span>
<span class="lineNum">     145 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_GRAPHS: {
<span class="lineNum">     146 </span><span class="lineNoCov">          0 :     std::vector&lt;std::shared_ptr&lt;Graph&gt;&gt; graphs;</span>
<span class="lineNum">     147 </span><span class="lineNoCov">          0 :     graphs.reserve(ap.graphs_size());</span>
<span class="lineNum">     148 </span><span class="lineNoCov">          0 :     for (int i = 0; i &lt; ap.graphs_size(); i++) {</span>
<span class="lineNum">     149 </span><span class="lineNoCov">          0 :       graphs.push_back(graphProtoToGraph(ap.graphs(i), true));</span>
<span class="lineNum">     150 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     151 </span><span class="lineNoCov">          0 :     n-&gt;gs_(sym, std::move(graphs));</span>
<span class="lineNum">     152 </span>            :     break;
<span class="lineNum">     153 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     154 </span>            :   case ONNX_NAMESPACE::AttributeProto_AttributeType_UNDEFINED:
<span class="lineNum">     155 </span><span class="lineNoCov">          0 :     abort();</span>
<span class="lineNum">     156 </span>            :     break;
<span class="lineNum">     157 </span>            :   }
<a name="158"><span class="lineNum">     158 </span><span class="lineCov">         54 : }</span></a>
<span class="lineNum">     159 </span>            : 
<span class="lineNum">     160 </span>            : void convertAttributes(ONNX_NAMESPACE::NodeProto &amp; np, Node * n) {
<span class="lineNum">     161 </span><span class="lineCov">        258 :   for (int i = 0; i &lt; np.attribute_size(); i++) {</span>
<span class="lineNum">     162 </span><span class="lineCov">         54 :     convertAttribute(np.attribute(i), n);</span>
<span class="lineNum">     163 </span><span class="lineCov">         54 :   }</span>
<a name="164"><span class="lineNum">     164 </span><span class="lineCov">         75 : }</span></a>
<span class="lineNum">     165 </span>            : 
<span class="lineNum">     166 </span>            : std::vector&lt;Dimension&gt; tensorShapeProtoToDimensions(const ONNX_NAMESPACE::TensorShapeProto &amp; tsp) {
<span class="lineNum">     167 </span><span class="lineCov">         99 :   std::vector&lt;Dimension&gt; dims;</span>
<span class="lineNum">     168 </span><span class="lineCov">        198 :   dims.reserve(tsp.dim_size());</span>
<span class="lineNum">     169 </span><span class="lineCov">        918 :   for (int i = 0; i &lt; tsp.dim_size(); i++) {</span>
<span class="lineNum">     170 </span><span class="lineCov">        621 :     if (tsp.dim(i).has_dim_value()) {</span>
<span class="lineNum">     171 </span><span class="lineCov">       1035 :       dims.push_back(Dimension(static_cast&lt;int&gt;(tsp.dim(i).dim_value())));</span>
<span class="lineNum">     172 </span><span class="lineCov">        207 :     } else {</span>
<span class="lineNum">     173 </span><span class="lineNoCov">          0 :       dims.push_back(Dimension(tsp.dim(i).dim_param()));</span>
<span class="lineNum">     174 </span>            :     }
<span class="lineNum">     175 </span><span class="lineCov">        207 :   }</span>
<span class="lineNum">     176 </span><span class="lineCov">         99 :   return dims;</span>
<a name="177"><span class="lineNum">     177 </span><span class="lineCov">        198 : }</span></a>
<span class="lineNum">     178 </span>            : 
<span class="lineNum">     179 </span>            : std::unique_ptr&lt;Graph&gt; graphProtoToGraph(const ONNX_NAMESPACE::GraphProto&amp; gp, bool nested) {
<span class="lineNum">     180 </span><span class="lineCov">         56 :   std::unique_ptr&lt;Graph&gt; g(new Graph());</span>
<span class="lineNum">     181 </span>            : 
<span class="lineNum">     182 </span><span class="lineCov">         56 :   if (gp.has_name()) {</span>
<span class="lineNum">     183 </span><span class="lineCov">        112 :     g-&gt;setName(gp.name());</span>
<span class="lineNum">     184 </span><span class="lineCov">         28 :   }</span>
<span class="lineNum">     185 </span><span class="lineCov">         56 :   if (gp.has_doc_string()) {</span>
<span class="lineNum">     186 </span><span class="lineNoCov">          0 :     g-&gt;setDocString(gp.doc_string());</span>
<span class="lineNum">     187 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     188 </span>            : 
<span class="lineNum">     189 </span>            :   // Values are created (as in `new Value(..)`) by the Node that
<span class="lineNum">     190 </span>            :   // outputs them. Therefore we initialize the Nodes and Values in
<span class="lineNum">     191 </span>            :   // several stages.
<span class="lineNum">     192 </span>            :   //
<span class="lineNum">     193 </span>            :   // 1) add all input (to the graph) Values, owned by the sentinel Param node
<span class="lineNum">     194 </span>            :   // 2) add all Nodes and their output Values, but don't intialize inputs
<span class="lineNum">     195 </span>            :   // 3) initialize inputs of all Nodes
<span class="lineNum">     196 </span>            :   // 4) initialize inputs of the Return sentinel node
<span class="lineNum">     197 </span>            :   // 5) fill in type info for graph outputs, and register them as outputs
<span class="lineNum">     198 </span>            :   // 5) fill in type info for Values from the value_info list in the graph
<span class="lineNum">     199 </span>            : 
<span class="lineNum">     200 </span>            :   // In ONNX proto land, Values are just strings. We are going to make
<span class="lineNum">     201 </span>            :   // objects out of them, and equal strings must be mapped to the same
<span class="lineNum">     202 </span>            :   // Value object.
<span class="lineNum">     203 </span><span class="lineCov">         28 :   std::unordered_map&lt;std::string, Value*&gt; value_by_name_of;</span>
<span class="lineNum">     204 </span>            : 
<span class="lineNum">     205 </span>            :   // We initialize Node inputs in a separate pass from the Nodes
<span class="lineNum">     206 </span>            :   // themselves. To do so, we need to have access to the names of the
<span class="lineNum">     207 </span>            :   // inputs.
<span class="lineNum">     208 </span><span class="lineCov">         28 :   std::unordered_map&lt;Node*, std::vector&lt;std::string&gt;&gt; inputs_by_node;</span>
<span class="lineNum">     209 </span>            : 
<span class="lineNum">     210 </span>            :   {
<span class="lineNum">     211 </span>            :     // ONNX represents optional arguments in two ways
<span class="lineNum">     212 </span>            :     //  - they are simply not privided
<span class="lineNum">     213 </span>            :     //  - OR the empty string is passed as the input name
<span class="lineNum">     214 </span>            :     // This is to handle that second case, which needs a dummy node to
<span class="lineNum">     215 </span>            :     // be representable in the graph IR.
<span class="lineNum">     216 </span><span class="lineCov">         84 :     auto * n = g-&gt;create(kUndefined, 1);</span>
<span class="lineNum">     217 </span><span class="lineCov">         28 :     g-&gt;appendNode(n);</span>
<span class="lineNum">     218 </span><span class="lineCov">        140 :     n-&gt;outputs()[0]-&gt;setUniqueName(&quot;&quot;);</span>
<span class="lineNum">     219 </span><span class="lineCov">        140 :     value_by_name_of[&quot;&quot;] = n-&gt;outputs()[0];</span>
<span class="lineNum">     220 </span>            :   }
<span class="lineNum">     221 </span>            : 
<span class="lineNum">     222 </span><span class="lineCov">        252 :   for (int i = 0; i &lt; gp.input_size(); i++) {</span>
<span class="lineNum">     223 </span><span class="lineCov">        112 :     auto vip = gp.input(i);</span>
<span class="lineNum">     224 </span><span class="lineCov">        112 :     auto v = g-&gt;addInput();</span>
<span class="lineNum">     225 </span><span class="lineCov">        224 :     v-&gt;setElemType(vip.type().tensor_type().elem_type());</span>
<span class="lineNum">     226 </span><span class="lineCov">        336 :     v-&gt;setSizes(tensorShapeProtoToDimensions(vip.type().tensor_type().shape()));</span>
<span class="lineNum">     227 </span><span class="lineCov">        224 :     v-&gt;setUniqueName(vip.name());</span>
<span class="lineNum">     228 </span><span class="lineCov">        168 :     value_by_name_of[vip.name()] = v;</span>
<span class="lineNum">     229 </span><span class="lineCov">         56 :   }</span>
<span class="lineNum">     230 </span>            : 
<span class="lineNum">     231 </span><span class="lineCov">        309 :   for (int i = 0; i &lt; gp.node_size(); i++) {</span>
<span class="lineNum">     232 </span><span class="lineCov">        150 :     auto np = gp.node(i);</span>
<span class="lineNum">     233 </span><span class="lineCov">        375 :     auto * n = g-&gt;create(Symbol(np.op_type()), /* num_outputs = */ np.output_size());</span>
<span class="lineNum">     234 </span><span class="lineCov">         75 :     g-&gt;appendNode(n);</span>
<span class="lineNum">     235 </span><span class="lineCov">        456 :     for (int j = 0; j &lt; np.output_size(); j++) {</span>
<span class="lineNum">     236 </span><span class="lineCov">        231 :       auto out = n-&gt;outputs()[j];</span>
<span class="lineNum">     237 </span>            :       // we don't know the real type here, so that's done in a later pass
<span class="lineNum">     238 </span><span class="lineCov">         77 :       out-&gt;setElemType(ONNX_NAMESPACE::TensorProto_DataType_UNDEFINED);</span>
<span class="lineNum">     239 </span><span class="lineCov">        308 :       out-&gt;setUniqueName(np.output(j));</span>
<span class="lineNum">     240 </span><span class="lineCov">        231 :       value_by_name_of[np.output(j)] = out;</span>
<span class="lineNum">     241 </span><span class="lineCov">         77 :     }</span>
<span class="lineNum">     242 </span><span class="lineCov">         68 :     convertAttributes(np, n);</span>
<span class="lineNum">     243 </span><span class="lineCov">         75 :     std::vector&lt;std::string&gt; inputs;</span>
<span class="lineNum">     244 </span><span class="lineCov">        150 :     inputs.reserve(np.input_size());</span>
<span class="lineNum">     245 </span><span class="lineCov">        519 :     for (int j = 0; j &lt; np.input_size(); j++) {</span>
<span class="lineNum">     246 </span><span class="lineCov">        196 :       inputs.push_back(np.input(j));</span>
<span class="lineNum">     247 </span><span class="lineCov">         98 :     }</span>
<span class="lineNum">     248 </span><span class="lineCov">        150 :     inputs_by_node[n] = inputs;</span>
<span class="lineNum">     249 </span><span class="lineCov">        150 :     if (np.has_doc_string()) {</span>
<span class="lineNum">     250 </span><span class="lineNoCov">          0 :       n-&gt;setDocString(np.doc_string());</span>
<span class="lineNum">     251 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     252 </span><span class="lineCov">        150 :     if (np.has_name()) {</span>
<span class="lineNum">     253 </span><span class="lineNoCov">          0 :       n-&gt;setName(np.name());</span>
<span class="lineNum">     254 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     255 </span><span class="lineCov">         75 :   }</span>
<span class="lineNum">     256 </span>            : 
<span class="lineNum">     257 </span><span class="lineCov">       1163 :   for (auto n : g-&gt;nodes()) {</span>
<span class="lineNum">     258 </span><span class="lineCov">        216 :     auto search = inputs_by_node.find(n);</span>
<span class="lineNum">     259 </span><span class="lineCov">        216 :     if (search == inputs_by_node.end()) {</span>
<span class="lineNum">     260 </span><span class="lineCov">         33 :       continue;</span>
<span class="lineNum">     261 </span>            :     }
<span class="lineNum">     262 </span><span class="lineCov">        617 :     for (auto input : search-&gt;second) {</span>
<span class="lineNum">     263 </span><span class="lineCov">        201 :       if (!value_by_name_of.count(input) &amp;&amp; nested) {</span>
<span class="lineNum">     264 </span>            :         // Undefined reference to an input in a nested block. This may be a
<span class="lineNum">     265 </span>            :         // captured value. Create a dummy node that we ignore later.
<span class="lineNum">     266 </span><span class="lineCov">         15 :         auto * undef = g-&gt;create(kCaptured, 1);</span>
<span class="lineNum">     267 </span><span class="lineCov">          5 :         g-&gt;appendNode(undef);</span>
<span class="lineNum">     268 </span><span class="lineCov">         25 :         undef-&gt;outputs()[0]-&gt;setUniqueName(input);</span>
<span class="lineNum">     269 </span><span class="lineCov">         20 :         value_by_name_of[input] = undef-&gt;outputs()[0];</span>
<span class="lineNum">     270 </span><span class="lineCov">          5 :       }</span>
<span class="lineNum">     271 </span>            : 
<span class="lineNum">     272 </span><span class="lineCov">        196 :       n-&gt;addInput(value_by_name_of.at(input));</span>
<span class="lineNum">     273 </span><span class="lineCov">         98 :     }</span>
<span class="lineNum">     274 </span>            :   }
<span class="lineNum">     275 </span>            : 
<span class="lineNum">     276 </span><span class="lineCov">        198 :   for (int i = 0; i &lt; gp.output_size(); i++) {</span>
<span class="lineNum">     277 </span><span class="lineCov">        304 :     value_by_name_of[gp.output(i).name()]-&gt;setElemType(gp.output(i).type().tensor_type().elem_type());</span>
<span class="lineNum">     278 </span><span class="lineCov">        380 :     value_by_name_of[gp.output(i).name()]-&gt;setSizes(tensorShapeProtoToDimensions(gp.output(i).type().tensor_type().shape()));</span>
<span class="lineNum">     279 </span><span class="lineCov">        152 :     g-&gt;registerOutput(value_by_name_of[gp.output(i).name()]);</span>
<span class="lineNum">     280 </span><span class="lineCov">         38 :   }</span>
<span class="lineNum">     281 </span>            : 
<span class="lineNum">     282 </span><span class="lineCov">         99 :   for (int i = 0; i &lt; gp.value_info_size(); i++) {</span>
<span class="lineNum">     283 </span><span class="lineCov">         40 :     value_by_name_of[gp.value_info(i).name()]-&gt;setElemType(gp.value_info(i).type().tensor_type().elem_type());</span>
<span class="lineNum">     284 </span><span class="lineCov">         50 :     value_by_name_of[gp.value_info(i).name()]-&gt;setSizes(tensorShapeProtoToDimensions(gp.value_info(i).type().tensor_type().shape()));</span>
<span class="lineNum">     285 </span><span class="lineCov">          5 :   }</span>
<span class="lineNum">     286 </span>            : 
<span class="lineNum">     287 </span><span class="lineCov">         84 :   for (int i = 0; i &lt; gp.initializer_size(); i++) {</span>
<span class="lineNum">     288 </span><span class="lineNoCov">          0 :     auto init = tensorProtoToTensor(gp.initializer(i));</span>
<span class="lineNum">     289 </span><span class="lineNoCov">          0 :     g-&gt;addInitializer(init, init.name());</span>
<span class="lineNum">     290 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     291 </span>            : 
<span class="lineNum">     292 </span><span class="lineCov">         28 :   return g;</span>
<a name="293"><span class="lineNum">     293 </span><span class="lineCov">         56 : }</span></a>
<span class="lineNum">     294 </span>            : 
<span class="lineNum">     295 </span>            : std::unique_ptr&lt;Graph&gt; ImportModelProto(const ONNX_NAMESPACE::ModelProto&amp; mp) {
<span class="lineNum">     296 </span><span class="lineCov">         20 :   if (!mp.has_ir_version()) {</span>
<span class="lineNum">     297 </span><span class="lineNoCov">          0 :     return nullptr;</span>
<span class="lineNum">     298 </span><span class="lineCov">         20 :   } else if (mp.ir_version() == 1) {</span>
<span class="lineNum">     299 </span><span class="lineNoCov">          0 :     return nullptr;</span>
<span class="lineNum">     300 </span>            :   }
<span class="lineNum">     301 </span>            : 
<span class="lineNum">     302 </span><span class="lineCov">         20 :   return graphProtoToGraph(mp.graph(), false);</span>
<span class="lineNum">     303 </span><span class="lineCov">         20 : }</span>
<span class="lineNum">     304 </span>            : 
<a name="305"><span class="lineNum">     305 </span>            : </a>
<span class="lineNum">     306 </span>            : // Part 2: convert IR to ONNX Protobuf
<span class="lineNum">     307 </span>            : std::string value_name(Value* n) {
<span class="lineNum">     308 </span><span class="lineCov">        236 :   return n-&gt;uniqueName();</span>
<span class="lineNum">     309 </span>            : }
<span class="lineNum">     310 </span>            : 
<a name="311"><span class="lineNum">     311 </span>            : void encodeGraph(ONNX_NAMESPACE::GraphProto * p_g, const std::shared_ptr&lt;Graph&gt; &amp; g);</a>
<span class="lineNum">     312 </span>            : 
<span class="lineNum">     313 </span>            : void encodeTensor(ONNX_NAMESPACE::TensorProto * p, const Tensor &amp; tensor) {
<span class="lineNum">     314 </span><span class="lineCov">         16 :   if (tensor.hasName()) {</span>
<span class="lineNum">     315 </span><span class="lineCov">         15 :     p-&gt;set_name(tensor.name());</span>
<span class="lineNum">     316 </span><span class="lineCov">         15 :   }</span>
<span class="lineNum">     317 </span><span class="lineCov">         16 :   if (tensor.is_segment()) {</span>
<span class="lineNum">     318 </span><span class="lineNoCov">          0 :     ONNX_NAMESPACE::TensorProto_Segment segment;</span>
<span class="lineNum">     319 </span><span class="lineNoCov">          0 :     segment.set_begin(tensor.segment_begin());</span>
<span class="lineNum">     320 </span><span class="lineNoCov">          0 :     segment.set_end(tensor.segment_end());</span>
<span class="lineNum">     321 </span><span class="lineNoCov">          0 :     p-&gt;mutable_segment()-&gt;CopyFrom(segment);</span>
<span class="lineNum">     322 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     323 </span><span class="lineCov">         44 :   for(auto d : tensor.sizes()) {</span>
<span class="lineNum">     324 </span><span class="lineCov">          3 :     p-&gt;add_dims(d);</span>
<span class="lineNum">     325 </span>            :   }
<span class="lineNum">     326 </span><span class="lineCov">         32 :   p-&gt;set_data_type(tensor.elem_type());</span>
<span class="lineNum">     327 </span><span class="lineCov">         32 :   switch(tensor.elem_type()) {</span>
<span class="lineNum">     328 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_FLOAT:
<span class="lineNum">     329 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_COMPLEX64: {
<span class="lineNum">     330 </span><span class="lineCov">         72 :     for (float x : tensor.floats()) {</span>
<span class="lineNum">     331 </span><span class="lineCov">         17 :       p-&gt;add_float_data(x);</span>
<span class="lineNum">     332 </span>            :     }
<span class="lineNum">     333 </span><span class="lineCov">          2 :     break;</span>
<span class="lineNum">     334 </span>            :   }
<span class="lineNum">     335 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_FLOAT16:
<span class="lineNum">     336 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_BOOL:
<span class="lineNum">     337 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT8:
<span class="lineNum">     338 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT16:
<span class="lineNum">     339 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT32:
<span class="lineNum">     340 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT8:
<span class="lineNum">     341 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT16: {
<span class="lineNum">     342 </span><span class="lineCov">         78 :     for (int32_t x : tensor.int32s()) {</span>
<span class="lineNum">     343 </span><span class="lineCov">         13 :       p-&gt;add_int32_data(x);</span>
<span class="lineNum">     344 </span>            :     }
<span class="lineNum">     345 </span><span class="lineCov">         13 :     break;</span>
<span class="lineNum">     346 </span>            :   }
<span class="lineNum">     347 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_INT64: {
<span class="lineNum">     348 </span><span class="lineCov">          6 :     for (int64_t x : tensor.int64s()) {</span>
<span class="lineNum">     349 </span><span class="lineCov">          1 :       p-&gt;add_int64_data(x);</span>
<span class="lineNum">     350 </span>            :     }
<span class="lineNum">     351 </span><span class="lineCov">          1 :     break;</span>
<span class="lineNum">     352 </span>            :   }
<span class="lineNum">     353 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT32:
<span class="lineNum">     354 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UINT64: {
<span class="lineNum">     355 </span><span class="lineNoCov">          0 :     for (uint64_t x : tensor.uint64s()) {</span>
<span class="lineNum">     356 </span><span class="lineNoCov">          0 :       p-&gt;add_uint64_data(x);</span>
<span class="lineNum">     357 </span>            :     }
<span class="lineNum">     358 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">     359 </span>            :   }
<span class="lineNum">     360 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_DOUBLE:
<span class="lineNum">     361 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_COMPLEX128: {
<span class="lineNum">     362 </span><span class="lineNoCov">          0 :     for (double x : tensor.doubles()) {</span>
<span class="lineNum">     363 </span><span class="lineNoCov">          0 :       p-&gt;add_double_data(x);</span>
<span class="lineNum">     364 </span>            :     }
<span class="lineNum">     365 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">     366 </span>            :   }
<span class="lineNum">     367 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_STRING: {
<span class="lineNum">     368 </span><span class="lineNoCov">          0 :     for (const std::string&amp; x : tensor.strings()) {</span>
<span class="lineNum">     369 </span><span class="lineNoCov">          0 :       p-&gt;add_string_data(x);</span>
<span class="lineNum">     370 </span>            :     }
<span class="lineNum">     371 </span><span class="lineNoCov">          0 :     break;</span>
<span class="lineNum">     372 </span>            :   }
<span class="lineNum">     373 </span>            :   case ONNX_NAMESPACE::TensorProto_DataType_UNDEFINED:
<span class="lineNum">     374 </span><span class="lineNoCov">          0 :     abort();</span>
<span class="lineNum">     375 </span>            :   }
<span class="lineNum">     376 </span><span class="lineCov">         16 :   if (!tensor.raw().empty()) {</span>
<span class="lineNum">     377 </span><span class="lineNoCov">          0 :     p-&gt;set_raw_data(tensor.raw());</span>
<span class="lineNum">     378 </span><span class="lineNoCov">          0 :   }</span>
<a name="379"><span class="lineNum">     379 </span><span class="lineCov">         16 : }</span></a>
<span class="lineNum">     380 </span>            : 
<span class="lineNum">     381 </span>            : void addAttribute(ONNX_NAMESPACE::NodeProto * n_p, Node * n, Symbol name) {
<span class="lineNum">     382 </span><span class="lineCov">         80 :   auto attr = n_p-&gt;add_attribute();</span>
<span class="lineNum">     383 </span><span class="lineCov">         80 :   attr-&gt;set_name(name.toString());</span>
<span class="lineNum">     384 </span><span class="lineCov">         80 :   switch(n-&gt;kindOf(name)) {</span>
<span class="lineNum">     385 </span>            :     case AttributeKind::f:
<span class="lineNum">     386 </span><span class="lineNoCov">          0 :       attr-&gt;set_f(static_cast&lt;float&gt;(n-&gt;f(name)));</span>
<span class="lineNum">     387 </span><span class="lineNoCov">          0 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_FLOAT);</span>
<span class="lineNum">     388 </span><span class="lineNoCov">          0 :       break;</span>
<span class="lineNum">     389 </span>            :     case AttributeKind::fs:
<span class="lineNum">     390 </span><span class="lineNoCov">          0 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_FLOATS);</span>
<span class="lineNum">     391 </span><span class="lineNoCov">          0 :       for(auto &amp; v : n-&gt;fs(name))</span>
<span class="lineNum">     392 </span><span class="lineNoCov">          0 :         attr-&gt;add_floats(static_cast&lt;float&gt;(v));</span>
<span class="lineNum">     393 </span><span class="lineNoCov">          0 :       break;</span>
<span class="lineNum">     394 </span>            :     case AttributeKind::i:
<span class="lineNum">     395 </span><span class="lineCov">          8 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_INT);</span>
<span class="lineNum">     396 </span><span class="lineCov">          8 :       attr-&gt;set_i(n-&gt;i(name));</span>
<span class="lineNum">     397 </span><span class="lineCov">          8 :       break;</span>
<span class="lineNum">     398 </span>            :     case AttributeKind::is:
<span class="lineNum">     399 </span><span class="lineCov">          6 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_INTS);</span>
<span class="lineNum">     400 </span><span class="lineCov">         84 :       for(auto &amp; v : n-&gt;is(name))</span>
<span class="lineNum">     401 </span><span class="lineCov">         18 :         attr-&gt;add_ints(v);</span>
<span class="lineNum">     402 </span><span class="lineCov">          6 :       break;</span>
<span class="lineNum">     403 </span>            :     case AttributeKind::s:
<span class="lineNum">     404 </span><span class="lineNoCov">          0 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_STRING);</span>
<span class="lineNum">     405 </span><span class="lineNoCov">          0 :       attr-&gt;set_s(n-&gt;s(name));</span>
<span class="lineNum">     406 </span><span class="lineNoCov">          0 :       break;</span>
<span class="lineNum">     407 </span>            :     case AttributeKind::ss:
<span class="lineNum">     408 </span><span class="lineCov">          2 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_STRINGS);</span>
<span class="lineNum">     409 </span><span class="lineCov">         20 :       for(auto &amp; v : n-&gt;ss(name))</span>
<span class="lineNum">     410 </span><span class="lineCov">          4 :         attr-&gt;add_strings(v);</span>
<span class="lineNum">     411 </span><span class="lineCov">          2 :       break;</span>
<span class="lineNum">     412 </span>            :     case AttributeKind::t: {
<span class="lineNum">     413 </span><span class="lineCov">         16 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_TENSOR);</span>
<span class="lineNum">     414 </span><span class="lineCov">         16 :       auto t = attr-&gt;mutable_t();</span>
<span class="lineNum">     415 </span><span class="lineCov">         16 :       encodeTensor(t, n-&gt;t(name));</span>
<span class="lineNum">     416 </span><span class="lineCov">         16 :     } break;</span>
<span class="lineNum">     417 </span>            :     case AttributeKind::ts:
<span class="lineNum">     418 </span><span class="lineNoCov">          0 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_TENSORS);</span>
<span class="lineNum">     419 </span><span class="lineNoCov">          0 :       for(auto &amp; v : n-&gt;ts(name)) {</span>
<span class="lineNum">     420 </span><span class="lineNoCov">          0 :         auto t = attr-&gt;add_tensors();</span>
<span class="lineNum">     421 </span><span class="lineNoCov">          0 :         encodeTensor(t, v);</span>
<span class="lineNum">     422 </span>            :       }
<span class="lineNum">     423 </span><span class="lineNoCov">          0 :       break;</span>
<span class="lineNum">     424 </span>            :     case AttributeKind::g: {
<span class="lineNum">     425 </span><span class="lineCov">          8 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_GRAPH);</span>
<span class="lineNum">     426 </span><span class="lineCov">          8 :       auto g = attr-&gt;mutable_g();</span>
<span class="lineNum">     427 </span><span class="lineCov">          8 :       encodeGraph(g, n-&gt;g(name));</span>
<span class="lineNum">     428 </span><span class="lineCov">          8 :     } break;</span>
<span class="lineNum">     429 </span>            :     case AttributeKind::gs:
<span class="lineNum">     430 </span><span class="lineNoCov">          0 :       attr-&gt;set_type(ONNX_NAMESPACE::AttributeProto_AttributeType_GRAPHS);</span>
<span class="lineNum">     431 </span><span class="lineNoCov">          0 :       for(auto &amp; v : n-&gt;gs(name)) {</span>
<span class="lineNum">     432 </span><span class="lineNoCov">          0 :         auto g = attr-&gt;add_graphs();</span>
<span class="lineNum">     433 </span><span class="lineNoCov">          0 :         encodeGraph(g, v);</span>
<span class="lineNum">     434 </span>            :       }
<span class="lineNum">     435 </span><span class="lineNoCov">          0 :       break;</span>
<span class="lineNum">     436 </span>            :   }
<a name="437"><span class="lineNum">     437 </span><span class="lineCov">         40 : }</span></a>
<span class="lineNum">     438 </span>            : 
<span class="lineNum">     439 </span>            : void encodeTypeProtoTensorType(ONNX_NAMESPACE::TypeProto_Tensor* tensor_type, Value* n) {
<span class="lineNum">     440 </span><span class="lineCov">        100 :   tensor_type-&gt;set_elem_type(n-&gt;elemType());</span>
<span class="lineNum">     441 </span><span class="lineCov">        100 :   ONNX_NAMESPACE::TensorShapeProto* shape = tensor_type-&gt;mutable_shape();</span>
<span class="lineNum">     442 </span><span class="lineCov">       1020 :   for (const Dimension&amp; d : n-&gt;sizes()) {</span>
<span class="lineNum">     443 </span><span class="lineCov">        205 :     auto dim = shape-&gt;add_dim();</span>
<span class="lineNum">     444 </span><span class="lineCov">        205 :     if (d.is_int) {</span>
<span class="lineNum">     445 </span><span class="lineCov">        205 :       dim-&gt;set_dim_value(d.dim);</span>
<span class="lineNum">     446 </span><span class="lineCov">        205 :     } else {</span>
<span class="lineNum">     447 </span><span class="lineNoCov">          0 :       dim-&gt;set_dim_param(d.param);</span>
<span class="lineNum">     448 </span>            :     }
<span class="lineNum">     449 </span>            :   }
<a name="450"><span class="lineNum">     450 </span><span class="lineCov">        100 : }</span></a>
<span class="lineNum">     451 </span>            : 
<span class="lineNum">     452 </span>            : void encodeValueInfo(ONNX_NAMESPACE::ValueInfoProto* v, Value* n) {
<span class="lineNum">     453 </span><span class="lineCov">        100 :   if (n-&gt;has_unique_name()) {</span>
<span class="lineNum">     454 </span><span class="lineCov">        198 :     v-&gt;set_name(value_name(n));</span>
<span class="lineNum">     455 </span><span class="lineCov">         99 :   }</span>
<span class="lineNum">     456 </span><span class="lineCov">        100 :   ONNX_NAMESPACE::TypeProto* t = v-&gt;mutable_type();</span>
<span class="lineNum">     457 </span><span class="lineCov">        100 :   ONNX_NAMESPACE::TypeProto_Tensor* tensor_type = t-&gt;mutable_tensor_type();</span>
<span class="lineNum">     458 </span><span class="lineCov">        100 :   encodeTypeProtoTensorType(tensor_type, n);</span>
<a name="459"><span class="lineNum">     459 </span><span class="lineCov">        100 : }</span></a>
<span class="lineNum">     460 </span>            : 
<span class="lineNum">     461 </span>            : void encodeGraph(ONNX_NAMESPACE::GraphProto * p_g, const std::shared_ptr&lt;Graph&gt; &amp; g) {
<span class="lineNum">     462 </span><span class="lineCov">         28 :   ONNX_ASSERT(p_g != nullptr);</span>
<span class="lineNum">     463 </span>            : 
<span class="lineNum">     464 </span><span class="lineCov">         28 :   if (g-&gt;has_name()) {</span>
<span class="lineNum">     465 </span><span class="lineCov">         28 :     p_g-&gt;set_name(g-&gt;name());</span>
<span class="lineNum">     466 </span><span class="lineCov">         28 :   }</span>
<span class="lineNum">     467 </span>            : 
<span class="lineNum">     468 </span><span class="lineCov">         28 :   if (g-&gt;has_doc_string()) {</span>
<span class="lineNum">     469 </span><span class="lineNoCov">          0 :     p_g-&gt;set_doc_string(g-&gt;docString());</span>
<span class="lineNum">     470 </span><span class="lineNoCov">          0 :   }</span>
<span class="lineNum">     471 </span>            : 
<span class="lineNum">     472 </span><span class="lineCov">        284 :   for (auto input : g-&gt;inputs()) {</span>
<span class="lineNum">     473 </span><span class="lineCov">         57 :     ONNX_NAMESPACE::ValueInfoProto* v = p_g-&gt;add_input();</span>
<span class="lineNum">     474 </span><span class="lineCov">         57 :     encodeValueInfo(v, input);</span>
<span class="lineNum">     475 </span>            :   }
<span class="lineNum">     476 </span><span class="lineCov">        208 :   for (auto output : g-&gt;outputs()) {</span>
<span class="lineNum">     477 </span><span class="lineCov">         38 :     ONNX_NAMESPACE::ValueInfoProto* v = p_g-&gt;add_output();</span>
<span class="lineNum">     478 </span><span class="lineCov">         38 :     encodeValueInfo(v, output);</span>
<span class="lineNum">     479 </span>            :   }
<span class="lineNum">     480 </span>            : 
<span class="lineNum">     481 </span><span class="lineCov">         28 :   std::unordered_set&lt;Value*&gt; graph_outputs(g-&gt;outputs().begin(), g-&gt;outputs().end());</span>
<span class="lineNum">     482 </span>            : 
<span class="lineNum">     483 </span><span class="lineCov">        992 :   for (auto node : g-&gt;nodes()) {</span>
<span class="lineNum">     484 </span><span class="lineCov">        539 :     if (node-&gt;kind() == kUndefined || node-&gt;kind() == kCaptured) {</span>
<span class="lineNum">     485 </span>            :       // Undefined nodes are used to represent optional inputs that are not provided.
<span class="lineNum">     486 </span><span class="lineCov">         33 :       continue;</span>
<span class="lineNum">     487 </span>            :     }
<span class="lineNum">     488 </span><span class="lineCov">        112 :     auto p_n = p_g-&gt;add_node();</span>
<span class="lineNum">     489 </span><span class="lineCov">        600 :     for(auto input : node-&gt;inputs()) {</span>
<span class="lineNum">     490 </span><span class="lineCov">        320 :       if (input-&gt;node()-&gt;kind() == kUndefined) {</span>
<span class="lineNum">     491 </span><span class="lineCov">          1 :         p_n-&gt;add_input(&quot;&quot;);</span>
<span class="lineNum">     492 </span><span class="lineCov">          1 :       } else {</span>
<span class="lineNum">     493 </span><span class="lineCov">        237 :         p_n-&gt;add_input(value_name(input));</span>
<span class="lineNum">     494 </span>            :       }
<span class="lineNum">     495 </span>            :     }
<span class="lineNum">     496 </span><span class="lineCov">        459 :     for(auto output : node-&gt;outputs()) {</span>
<span class="lineNum">     497 </span><span class="lineCov">        174 :       p_n-&gt;add_output(value_name(output));</span>
<span class="lineNum">     498 </span>            : 
<span class="lineNum">     499 </span>            :       // only save it if
<span class="lineNum">     500 </span>            :       //  - it has actual information worth saving
<span class="lineNum">     501 </span>            :       //  - it's not already saved in the graph outputs value info
<span class="lineNum">     502 </span><span class="lineCov">        174 :       if (graph_outputs.find(output) != graph_outputs.end()) {</span>
<span class="lineNum">     503 </span><span class="lineCov">         26 :         continue;</span>
<span class="lineNum">     504 </span>            :       }
<span class="lineNum">     505 </span><span class="lineCov">         91 :       if (output-&gt;elemType() == ONNX_NAMESPACE::TensorProto_DataType_UNDEFINED &amp;&amp;</span>
<span class="lineNum">     506 </span><span class="lineCov">         54 :           output-&gt;sizes().empty()) {</span>
<span class="lineNum">     507 </span><span class="lineCov">         27 :         continue;</span>
<span class="lineNum">     508 </span>            :       }
<span class="lineNum">     509 </span><span class="lineCov">         10 :       ONNX_NAMESPACE::ValueInfoProto* v = p_g-&gt;add_value_info();</span>
<span class="lineNum">     510 </span><span class="lineCov">          5 :       encodeValueInfo(v, output);</span>
<span class="lineNum">     511 </span>            :     }
<span class="lineNum">     512 </span><span class="lineCov">        168 :     p_n-&gt;set_op_type(node-&gt;kind().toString());</span>
<span class="lineNum">     513 </span><span class="lineCov">        376 :     for(auto attr_name : node-&gt;attributeNames()) {</span>
<span class="lineNum">     514 </span><span class="lineCov">         32 :       addAttribute(p_n, node, attr_name);</span>
<span class="lineNum">     515 </span>            :     }
<span class="lineNum">     516 </span><span class="lineCov">        112 :     if (node-&gt;has_doc_string()) {</span>
<span class="lineNum">     517 </span><span class="lineNoCov">          0 :       p_n-&gt;set_doc_string(node-&gt;docString());</span>
<span class="lineNum">     518 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     519 </span><span class="lineCov">        112 :     if (node-&gt;has_name()) {</span>
<span class="lineNum">     520 </span><span class="lineNoCov">          0 :       p_n-&gt;set_name(node-&gt;name());</span>
<span class="lineNum">     521 </span><span class="lineNoCov">          0 :     }</span>
<span class="lineNum">     522 </span>            :   }
<span class="lineNum">     523 </span>            : 
<span class="lineNum">     524 </span><span class="lineCov">         56 :   auto num_initializers = g-&gt;initializers().size();</span>
<span class="lineNum">     525 </span><span class="lineCov">         56 :   for (unsigned int i = 0; i &lt; num_initializers; i++) {</span>
<span class="lineNum">     526 </span><span class="lineNoCov">          0 :     auto p = p_g-&gt;add_initializer();</span>
<span class="lineNum">     527 </span><span class="lineNoCov">          0 :     p-&gt;set_name(g-&gt;initializer_names()[i]);</span>
<span class="lineNum">     528 </span><span class="lineNoCov">          0 :     encodeTensor(p, g-&gt;initializers()[i]);</span>
<span class="lineNum">     529 </span><span class="lineNoCov">          0 :   }</span>
<a name="530"><span class="lineNum">     530 </span><span class="lineCov">         28 : }</span></a>
<span class="lineNum">     531 </span>            : 
<span class="lineNum">     532 </span>            : void ExportModelProto(ONNX_NAMESPACE::ModelProto* p_m, const std::shared_ptr&lt;Graph&gt;&amp; g) {
<span class="lineNum">     533 </span><span class="lineCov">         20 :   ONNX_NAMESPACE::GraphProto* p_g = p_m-&gt;mutable_graph();</span>
<span class="lineNum">     534 </span><span class="lineCov">         20 :   encodeGraph(p_g, g);</span>
<span class="lineNum">     535 </span><span class="lineCov">         20 : }</span>
<span class="lineNum">     536 </span>            : 
<span class="lineNum">     537 </span>            : } // namespace ONNX_NAMESPACE
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
