<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - onnx-coverage.info - onnx/optimizer/passes/fuse_add_bias_into_conv.h</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">onnx/optimizer/passes</a> - fuse_add_bias_into_conv.h<span style="font-size: 80%;"> (source / <a href="fuse_add_bias_into_conv.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">onnx-coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">71</td>
            <td class="headerCovTableEntry">78</td>
            <td class="headerCovTableEntryHi">91.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2018-05-11 14:21:51</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // ATTENTION: The code in this file is highly EXPERIMENTAL.</a>
<span class="lineNum">       2 </span>            : // Adventurous users should note that the APIs will probably change.
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : #pragma once
<span class="lineNum">       5 </span>            : 
<span class="lineNum">       6 </span>            : // Before:
<span class="lineNum">       7 </span>            : //   Z = Conv(X, Y)
<span class="lineNum">       8 </span>            : //   B = Z + A
<span class="lineNum">       9 </span>            : // After:
<span class="lineNum">      10 </span>            : //   B = Conv(X, Y, A)
<span class="lineNum">      11 </span>            : //
<span class="lineNum">      12 </span>            : // the pass can handle the following cases:
<span class="lineNum">      13 </span>            : //   case 1: A is 1D tensor and A.dim[0] == Z.dim[1]
<span class="lineNum">      14 </span>            : //   case 2: A is 1-element 1D tensor
<span class="lineNum">      15 </span>            : 
<span class="lineNum">      16 </span>            : 
<span class="lineNum">      17 </span>            : 
<span class="lineNum">      18 </span>            : #include &quot;onnx/optimizer/passes/optimize_pass.h&quot;
<span class="lineNum">      19 </span>            : 
<a name="20"><span class="lineNum">      20 </span>            : namespace ONNX_NAMESPACE { namespace optimization {</a>
<a name="21"><span class="lineNum">      21 </span>            : </a>
<span class="lineNum">      22 </span><span class="lineCov">          3 : struct FuseAddBiasIntoConv final : public OptimizePass {</span>
<span class="lineNum">      23 </span>            :   explicit FuseAddBiasIntoConv()
<span class="lineNum">      24 </span><span class="lineCov">          3 :     : OptimizePass(&quot;fuse_add_bias_into_conv&quot;, API_TYPE::IR) {</span>
<a name="25"><span class="lineNum">      25 </span><span class="lineCov">          2 :   }</span></a>
<span class="lineNum">      26 </span>            : 
<span class="lineNum">      27 </span>            :   void fuse_add_bias_into_conv(Graph&amp; graph) {
<span class="lineNum">      28 </span><span class="lineCov">          8 :     int size_lack_count = 0;</span>
<a name="29"><span class="lineNum">      29 </span><span class="lineCov">         74 :     for (auto it = graph.begin(); it != graph.end(); ++it) {</span></a>
<span class="lineNum">      30 </span><span class="lineCov">         28 :       auto* n = *it;</span>
<span class="lineNum">      31 </span><span class="lineCov">         58 :       DescendOnGraphAttributes(n, [this](Graph&amp; g){fuse_add_bias_into_conv(g);});</span>
<span class="lineNum">      32 </span><span class="lineCov">         66 :       if (n-&gt;kind() == kAdd &amp;&amp; n-&gt;inputs()[0]-&gt;node()-&gt;kind() == kConv</span>
<span class="lineNum">      33 </span><span class="lineCov">         16 :           &amp;&amp; n-&gt;inputs()[0]-&gt;node()-&gt;inputs().size() == 2) {</span>
<span class="lineNum">      34 </span>            :         // due to current broadcasting's constraint, Conv has to be the first oprand
<span class="lineNum">      35 </span><span class="lineCov">          8 :         auto orig_conv = n-&gt;inputs()[0];</span>
<span class="lineNum">      36 </span><span class="lineCov">          8 :         auto orig_bias = n-&gt;inputs()[1];</span>
<span class="lineNum">      37 </span>            :         // check if bias is Const or in graph's initializers
<span class="lineNum">      38 </span><span class="lineCov">         15 :         if (orig_bias-&gt;node()-&gt;kind() != kConstant</span>
<span class="lineNum">      39 </span><span class="lineCov">         15 :             &amp;&amp; orig_bias-&gt;node()-&gt;kind() != kParam) {</span>
<span class="lineNum">      40 </span><span class="lineNoCov">          0 :           continue;</span>
<span class="lineNum">      41 </span>            :         }
<span class="lineNum">      42 </span>            :         // check if conv is only used by Add
<span class="lineNum">      43 </span><span class="lineCov">          8 :         if (orig_conv-&gt;uses().size() &gt; 1) {</span>
<span class="lineNum">      44 </span><span class="lineNoCov">          0 :           continue;</span>
<span class="lineNum">      45 </span>            :         }
<span class="lineNum">      46 </span><span class="lineCov">          8 :         auto conv_shape = orig_conv-&gt;sizes();</span>
<span class="lineNum">      47 </span><span class="lineCov">         16 :         auto bias_shape = orig_bias-&gt;sizes();</span>
<span class="lineNum">      48 </span><span class="lineCov">         40 :         auto weight_shape = orig_conv-&gt;node()-&gt;inputs()[1]-&gt;sizes();</span>
<span class="lineNum">      49 </span><span class="lineCov">          8 :         int64_t M = -1;</span>
<span class="lineNum">      50 </span>            :         // try to get feature M from conv_shape
<span class="lineNum">      51 </span><span class="lineCov">         14 :         if (conv_shape.size() &gt; 1 &amp;&amp; conv_shape[1].is_int) {</span>
<span class="lineNum">      52 </span><span class="lineCov">          6 :           M = conv_shape[1].dim;</span>
<span class="lineNum">      53 </span><span class="lineCov">          3 :         }</span>
<span class="lineNum">      54 </span>            :         // try to get feature M from weight_shape
<span class="lineNum">      55 </span><span class="lineCov">         22 :         if (weight_shape.size() &gt; 0 &amp;&amp; weight_shape[0].is_int) {</span>
<span class="lineNum">      56 </span><span class="lineCov">         18 :           ONNX_ASSERT(M == -1 || M == weight_shape[0].dim);</span>
<span class="lineNum">      57 </span><span class="lineCov">         14 :           M = weight_shape[0].dim;</span>
<span class="lineNum">      58 </span><span class="lineCov">          7 :         }</span>
<span class="lineNum">      59 </span><span class="lineCov">         32 :         if (M == -1 || bias_shape.size() == 0 || !bias_shape[0].is_int) {</span>
<span class="lineNum">      60 </span>            :           // No enough information, bail out
<span class="lineNum">      61 </span><span class="lineNoCov">          0 :           size_lack_count += 1;</span>
<span class="lineNum">      62 </span><span class="lineNoCov">          0 :           continue;</span>
<span class="lineNum">      63 </span>            :         }
<span class="lineNum">      64 </span><span class="lineCov">          8 :         if (bias_shape.size() == 1) {</span>
<span class="lineNum">      65 </span><span class="lineCov">         42 :           ONNX_ASSERT(n-&gt;hasAttribute(kbroadcast) &amp;&amp; n-&gt;i(kbroadcast) == static_cast&lt;int64_t&gt;(1));</span>
<span class="lineNum">      66 </span><span class="lineCov">         23 :           bool able_to_optimize = bias_shape[0].dim == 1 ||</span>
<span class="lineNum">      67 </span><span class="lineCov">         34 :             (bias_shape[0].dim == M &amp;&amp; (!n-&gt;hasAttribute(kaxis) || n-&gt;i(kaxis) == 1));</span>
<span class="lineNum">      68 </span><span class="lineCov">          6 :           if (!able_to_optimize) {</span>
<span class="lineNum">      69 </span><span class="lineCov">          1 :             continue;</span>
<span class="lineNum">      70 </span>            :           }
<span class="lineNum">      71 </span>            :           // move the bias before Conv.
<span class="lineNum">      72 </span>            :           // if necessary, insert tile before Conv (after bias)
<span class="lineNum">      73 </span><span class="lineCov">         24 :           if (orig_bias-&gt;node()-&gt;kind() != kParam &amp;&amp; orig_conv-&gt;node()-&gt;isBefore(orig_bias-&gt;node())) {</span>
<span class="lineNum">      74 </span><span class="lineCov">          3 :             orig_bias-&gt;node()-&gt;moveBefore(orig_conv-&gt;node());</span>
<span class="lineNum">      75 </span><span class="lineCov">          1 :           }</span>
<span class="lineNum">      76 </span><span class="lineCov">         10 :           if (bias_shape[0].dim == 1) {</span>
<span class="lineNum">      77 </span><span class="lineCov">          3 :             Symbol sym = Symbol(&quot;value&quot;);</span>
<span class="lineNum">      78 </span><span class="lineCov">          3 :             Node* constant1 = graph.create(kConstant, 1);</span>
<span class="lineNum">      79 </span><span class="lineCov">          1 :             Tensor t1;</span>
<span class="lineNum">      80 </span><span class="lineCov">          2 :             t1.sizes().push_back(static_cast&lt;int64_t&gt;(1));</span>
<span class="lineNum">      81 </span><span class="lineCov">          2 :             t1.int64s().push_back(M);</span>
<span class="lineNum">      82 </span><span class="lineCov">          2 :             t1.elem_type() = TensorProto_DataType_INT64;</span>
<span class="lineNum">      83 </span><span class="lineCov">          1 :             constant1-&gt;t_(sym, t1);</span>
<span class="lineNum">      84 </span><span class="lineCov">          4 :             std::vector&lt;Dimension&gt; s1 = {1};</span>
<span class="lineNum">      85 </span><span class="lineCov">          4 :             constant1-&gt;output()-&gt;setSizes(s1);</span>
<span class="lineNum">      86 </span><span class="lineCov">          2 :             constant1-&gt;output()-&gt;setElemType(TensorProto_DataType_INT64);</span>
<span class="lineNum">      87 </span><span class="lineCov">          2 :             constant1-&gt;insertBefore(orig_conv-&gt;node());</span>
<span class="lineNum">      88 </span><span class="lineCov">          3 :             Node* tile = graph.create(kTile, 1);</span>
<span class="lineNum">      89 </span><span class="lineCov">          1 :             tile-&gt;addInput(orig_bias);</span>
<span class="lineNum">      90 </span><span class="lineCov">          2 :             tile-&gt;addInput(constant1-&gt;output());</span>
<span class="lineNum">      91 </span><span class="lineCov">          2 :             tile-&gt;insertBefore(orig_conv-&gt;node());</span>
<span class="lineNum">      92 </span><span class="lineCov">          3 :             orig_conv-&gt;node()-&gt;addInput(tile-&gt;output());</span>
<span class="lineNum">      93 </span><span class="lineCov">         13 :           } else if (bias_shape[0].dim == M &amp;&amp;</span>
<span class="lineNum">      94 </span><span class="lineCov">         24 :               (!n-&gt;hasAttribute(kaxis) || n-&gt;i(kaxis) == 1)) { // default axis is 1</span>
<span class="lineNum">      95 </span><span class="lineCov">          8 :             orig_conv-&gt;node()-&gt;addInput(orig_bias);</span>
<span class="lineNum">      96 </span><span class="lineCov">          4 :           }</span>
<span class="lineNum">      97 </span><span class="lineCov">         22 :           if (orig_conv-&gt;sizes().size() == 0 &amp;&amp; n-&gt;output()-&gt;sizes().size() &gt; 0) {</span>
<span class="lineNum">      98 </span><span class="lineCov">         20 :             orig_conv-&gt;setSizes(n-&gt;output()-&gt;sizes());</span>
<span class="lineNum">      99 </span><span class="lineCov">          4 :           }</span>
<span class="lineNum">     100 </span><span class="lineCov">         15 :           if (n-&gt;output()-&gt;elemType() != TensorProto_DataType_UNDEFINED) {</span>
<span class="lineNum">     101 </span><span class="lineCov">         15 :             orig_conv-&gt;setElemType(n-&gt;output()-&gt;elemType());</span>
<span class="lineNum">     102 </span><span class="lineCov">          5 :           }</span>
<span class="lineNum">     103 </span><span class="lineCov">         10 :           n-&gt;replaceAllUsesWith(orig_conv-&gt;node());</span>
<span class="lineNum">     104 </span><span class="lineCov">          5 :           it.destroyCurrent();</span>
<span class="lineNum">     105 </span><span class="lineCov">          5 :         }</span>
<span class="lineNum">     106 </span><span class="lineCov">         30 :       }</span>
<span class="lineNum">     107 </span><span class="lineCov">         28 :     }</span>
<span class="lineNum">     108 </span><span class="lineCov">          8 :     if (size_lack_count != 0) {</span>
<span class="lineNum">     109 </span><span class="lineNoCov">          0 :       std::cout &lt;&lt;</span>
<span class="lineNum">     110 </span>            :                 &quot;Warning: failed to fuse Add into Conv bias due to lack of size information.&quot;
<span class="lineNum">     111 </span><span class="lineNoCov">          0 :                 &lt;&lt; std::endl;</span>
<span class="lineNum">     112 </span><span class="lineNoCov">          0 :     }</span>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">          8 :   }</span></a>
<span class="lineNum">     114 </span>            : 
<span class="lineNum">     115 </span>            :   void optimize(Graph&amp; graph) override {
<span class="lineNum">     116 </span><span class="lineCov">          7 :     fuse_add_bias_into_conv(graph);</span>
<span class="lineNum">     117 </span><span class="lineCov">          7 :   }</span>
<span class="lineNum">     118 </span>            : };
<span class="lineNum">     119 </span>            : 
<span class="lineNum">     120 </span>            : }} // namespace ONNX_NAMESPACE::optimization
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
